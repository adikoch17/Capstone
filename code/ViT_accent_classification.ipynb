{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5840c308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c23d312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "import librosa\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a654cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 11\n",
    "input_shape = (128, 384, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccd384af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "340b1241",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = pd.read_csv(\"val_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9f65a8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, csv_file, batch_size=32, num_classes=11, sample_rate=22050, duration=10.0, shuffle=True, n_mels=128):\n",
    "        self.csv_file = csv_file\n",
    "        self.batch_size = batch_size\n",
    "        self.num_classes = num_classes\n",
    "        self.sample_rate = sample_rate\n",
    "        self.duration = duration\n",
    "        self.shuffle = shuffle\n",
    "        self.n_mels  = n_mels\n",
    "        \n",
    "        # Read the CSV file\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Get the unique class labels\n",
    "        self.classes = sorted(self.data['class_label'].unique())\n",
    "        \n",
    "        # Create a dictionary to map class labels to integers\n",
    "        self.class_to_int = dict(zip(self.classes, range(len(self.classes))))\n",
    "        \n",
    "        # Shuffle the data if requested\n",
    "        if self.shuffle:\n",
    "            self.data = self.data.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Return the number of batches\n",
    "        return int(np.ceil(len(self.data) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get the batch of file paths and labels\n",
    "        batch_data = self.data[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_data = batch_data.reset_index()\n",
    "        \n",
    "        # Initialize the arrays for the audio data and labels\n",
    "        batch_x = np.zeros((len(batch_data), self.n_mels, 431,1))\n",
    "        batch_y = np.zeros((len(batch_data), self.num_classes))\n",
    "        \n",
    "        # Load the audio files and their corresponding labels\n",
    "        for i, row in batch_data.iterrows():\n",
    "            file_path = row['file_path']\n",
    "            class_label = row['class_label']\n",
    "            \n",
    "            # Load the audio file\n",
    "            signal, sr = librosa.load(file_path, sr=self.sample_rate, mono=True)\n",
    "            \n",
    "            # Pad or truncate the signal to the desired length\n",
    "            signal = librosa.util.fix_length(signal, size=self.sample_rate * self.duration)\n",
    "            \n",
    "            # Convert the audio file to spectrogram\n",
    "            S = librosa.feature.melspectrogram(y=signal, sr=sr)\n",
    "            S_dB = np.array(librosa.power_to_db(S, ref=np.max))\n",
    "            S_dB = S_dB.reshape(S_dB.shape[0],S_dB.shape[1],1)\n",
    "            \n",
    "            # Save the audio data and label to the batch arrays\n",
    "            batch_x[i, :] = S_dB\n",
    "            batch_y[i, :] = to_categorical(self.class_to_int[class_label], num_classes=self.num_classes)\n",
    "            \n",
    "#         batch_x.reshape(self.batch_size,batch_x.shape[0],batch_x.shape[1])\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "27bba197",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = AudioDataGenerator('train_data.csv', batch_size=32, num_classes=11, sample_rate=22050, duration=10, shuffle=True, n_mels=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "710db36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator = AudioDataGenerator('val_data.csv', batch_size=32, num_classes=11, sample_rate=22050, duration=10, shuffle=True, n_mels=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5d09ae",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dbee1b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "image_size_y=128\n",
    "image_size_x = 384\n",
    "patch_size_y = 128  # Size of the patches to be extract from the input images\n",
    "patch_size_x = 3\n",
    "num_patches = (image_size_y*image_size_x) // (patch_size_y*patch_size_x)\n",
    "print(num_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "51679502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "image_size_y = 384  # We'll resize input images to this size\n",
    "image_size_x = 128\n",
    "patch_size_y = 128  # Size of the patches to be extract from the input images\n",
    "patch_size_x = 16\n",
    "num_patches = (image_size_y*image_size_x) // (patch_size_y*patch_size_x)\n",
    "projection_dim = 128\n",
    "num_heads = 20\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [256, 128]  # Size of the dense layers of the final classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e797afc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "\n",
    "data_augmentation_resize = keras.Sequential(\n",
    "    [\n",
    "        layers.Resizing(image_size_y, image_size_x),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3884472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation='relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e6cb7cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size_x,_patch_size_y):\n",
    "        super().__init__()\n",
    "        self.patch_size_x = patch_size_x\n",
    "        self.patch_size_y = patch_size_y\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size_y, self.patch_size_x, 1],\n",
    "            strides=[1, self.patch_size_y, self.patch_size_x, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f815b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "        self.reshape_patches = layers.Reshape((num_patches, projection_dim))\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.reshape_patches(self.projection(patch))+ self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3dece33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier():\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Augment data.\n",
    "    augmented = data_augmentation_resize(inputs)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size_x,patch_size_y)(augmented)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        \n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(encoded_patches, encoded_patches)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x2, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.2)\n",
    "    # Classify outputs.\n",
    "    logits = layers.Dense(num_classes)(features)\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "39f31ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining metrics\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "76a3186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model):\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            f1_m,\n",
    "            precision_m, \n",
    "            recall_m\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs\n",
    "    )\n",
    "\n",
    "    loss, accuracy, f1_score, precision, recall = model.evaluate(val_generator)\n",
    "    print('Validation accuracy:', accuracy)\n",
    "    print('Validation loss:', loss)\n",
    "    print('Validation f1:', f1_score)\n",
    "    print('Validation precision:', precision)\n",
    "    print('Validation recall:', recall)\n",
    "\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6ed347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1716698a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_classifier = create_vit_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "93672d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, 384, 128, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " data_augmentation (Sequential)  (None, 384, 128, 1)  0          ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " patches_9 (Patches)            (None, None, 2048)   0           ['data_augmentation[5][0]']      \n",
      "                                                                                                  \n",
      " patch_encoder_7 (PatchEncoder)  (None, 24, 128)     262272      ['patches_9[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_56 (Multi  (None, 24, 128)     1318528     ['patch_encoder_7[0][0]',        \n",
      " HeadAttention)                                                   'patch_encoder_7[0][0]']        \n",
      "                                                                                                  \n",
      " add_112 (Add)                  (None, 24, 128)      0           ['multi_head_attention_56[0][0]',\n",
      "                                                                  'patch_encoder_7[0][0]']        \n",
      "                                                                                                  \n",
      " dense_141 (Dense)              (None, 24, 256)      33024       ['add_112[0][0]']                \n",
      "                                                                                                  \n",
      " dense_142 (Dense)              (None, 24, 128)      32896       ['dense_141[0][0]']              \n",
      "                                                                                                  \n",
      " add_113 (Add)                  (None, 24, 128)      0           ['dense_142[0][0]',              \n",
      "                                                                  'add_112[0][0]']                \n",
      "                                                                                                  \n",
      " multi_head_attention_57 (Multi  (None, 24, 128)     1318528     ['add_113[0][0]',                \n",
      " HeadAttention)                                                   'add_113[0][0]']                \n",
      "                                                                                                  \n",
      " add_114 (Add)                  (None, 24, 128)      0           ['multi_head_attention_57[0][0]',\n",
      "                                                                  'add_113[0][0]']                \n",
      "                                                                                                  \n",
      " dense_143 (Dense)              (None, 24, 256)      33024       ['add_114[0][0]']                \n",
      "                                                                                                  \n",
      " dense_144 (Dense)              (None, 24, 128)      32896       ['dense_143[0][0]']              \n",
      "                                                                                                  \n",
      " add_115 (Add)                  (None, 24, 128)      0           ['dense_144[0][0]',              \n",
      "                                                                  'add_114[0][0]']                \n",
      "                                                                                                  \n",
      " multi_head_attention_58 (Multi  (None, 24, 128)     1318528     ['add_115[0][0]',                \n",
      " HeadAttention)                                                   'add_115[0][0]']                \n",
      "                                                                                                  \n",
      " add_116 (Add)                  (None, 24, 128)      0           ['multi_head_attention_58[0][0]',\n",
      "                                                                  'add_115[0][0]']                \n",
      "                                                                                                  \n",
      " dense_145 (Dense)              (None, 24, 256)      33024       ['add_116[0][0]']                \n",
      "                                                                                                  \n",
      " dense_146 (Dense)              (None, 24, 128)      32896       ['dense_145[0][0]']              \n",
      "                                                                                                  \n",
      " add_117 (Add)                  (None, 24, 128)      0           ['dense_146[0][0]',              \n",
      "                                                                  'add_116[0][0]']                \n",
      "                                                                                                  \n",
      " multi_head_attention_59 (Multi  (None, 24, 128)     1318528     ['add_117[0][0]',                \n",
      " HeadAttention)                                                   'add_117[0][0]']                \n",
      "                                                                                                  \n",
      " add_118 (Add)                  (None, 24, 128)      0           ['multi_head_attention_59[0][0]',\n",
      "                                                                  'add_117[0][0]']                \n",
      "                                                                                                  \n",
      " dense_147 (Dense)              (None, 24, 256)      33024       ['add_118[0][0]']                \n",
      "                                                                                                  \n",
      " dense_148 (Dense)              (None, 24, 128)      32896       ['dense_147[0][0]']              \n",
      "                                                                                                  \n",
      " add_119 (Add)                  (None, 24, 128)      0           ['dense_148[0][0]',              \n",
      "                                                                  'add_118[0][0]']                \n",
      "                                                                                                  \n",
      " multi_head_attention_60 (Multi  (None, 24, 128)     1318528     ['add_119[0][0]',                \n",
      " HeadAttention)                                                   'add_119[0][0]']                \n",
      "                                                                                                  \n",
      " add_120 (Add)                  (None, 24, 128)      0           ['multi_head_attention_60[0][0]',\n",
      "                                                                  'add_119[0][0]']                \n",
      "                                                                                                  \n",
      " dense_149 (Dense)              (None, 24, 256)      33024       ['add_120[0][0]']                \n",
      "                                                                                                  \n",
      " dense_150 (Dense)              (None, 24, 128)      32896       ['dense_149[0][0]']              \n",
      "                                                                                                  \n",
      " add_121 (Add)                  (None, 24, 128)      0           ['dense_150[0][0]',              \n",
      "                                                                  'add_120[0][0]']                \n",
      "                                                                                                  \n",
      " multi_head_attention_61 (Multi  (None, 24, 128)     1318528     ['add_121[0][0]',                \n",
      " HeadAttention)                                                   'add_121[0][0]']                \n",
      "                                                                                                  \n",
      " add_122 (Add)                  (None, 24, 128)      0           ['multi_head_attention_61[0][0]',\n",
      "                                                                  'add_121[0][0]']                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_151 (Dense)              (None, 24, 256)      33024       ['add_122[0][0]']                \n",
      "                                                                                                  \n",
      " dense_152 (Dense)              (None, 24, 128)      32896       ['dense_151[0][0]']              \n",
      "                                                                                                  \n",
      " add_123 (Add)                  (None, 24, 128)      0           ['dense_152[0][0]',              \n",
      "                                                                  'add_122[0][0]']                \n",
      "                                                                                                  \n",
      " multi_head_attention_62 (Multi  (None, 24, 128)     1318528     ['add_123[0][0]',                \n",
      " HeadAttention)                                                   'add_123[0][0]']                \n",
      "                                                                                                  \n",
      " add_124 (Add)                  (None, 24, 128)      0           ['multi_head_attention_62[0][0]',\n",
      "                                                                  'add_123[0][0]']                \n",
      "                                                                                                  \n",
      " dense_153 (Dense)              (None, 24, 256)      33024       ['add_124[0][0]']                \n",
      "                                                                                                  \n",
      " dense_154 (Dense)              (None, 24, 128)      32896       ['dense_153[0][0]']              \n",
      "                                                                                                  \n",
      " add_125 (Add)                  (None, 24, 128)      0           ['dense_154[0][0]',              \n",
      "                                                                  'add_124[0][0]']                \n",
      "                                                                                                  \n",
      " multi_head_attention_63 (Multi  (None, 24, 128)     1318528     ['add_125[0][0]',                \n",
      " HeadAttention)                                                   'add_125[0][0]']                \n",
      "                                                                                                  \n",
      " add_126 (Add)                  (None, 24, 128)      0           ['multi_head_attention_63[0][0]',\n",
      "                                                                  'add_125[0][0]']                \n",
      "                                                                                                  \n",
      " dense_155 (Dense)              (None, 24, 256)      33024       ['add_126[0][0]']                \n",
      "                                                                                                  \n",
      " dense_156 (Dense)              (None, 24, 128)      32896       ['dense_155[0][0]']              \n",
      "                                                                                                  \n",
      " add_127 (Add)                  (None, 24, 128)      0           ['dense_156[0][0]',              \n",
      "                                                                  'add_126[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_135 (Layer  (None, 24, 128)     256         ['add_127[0][0]']                \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " flatten_7 (Flatten)            (None, 3072)         0           ['layer_normalization_135[0][0]']\n",
      "                                                                                                  \n",
      " dropout_61 (Dropout)           (None, 3072)         0           ['flatten_7[0][0]']              \n",
      "                                                                                                  \n",
      " dense_157 (Dense)              (None, 256)          786688      ['dropout_61[0][0]']             \n",
      "                                                                                                  \n",
      " dense_158 (Dense)              (None, 128)          32896       ['dense_157[0][0]']              \n",
      "                                                                                                  \n",
      " dense_159 (Dense)              (None, 11)           1419        ['dense_158[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,159,115\n",
      "Trainable params: 12,159,115\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vit_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fab36cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "447/447 [==============================] - 394s 868ms/step - loss: 9.8139 - accuracy: 0.2342 - f1_m: 0.2142 - precision_m: 0.1285 - recall_m: 0.6418\n",
      "Epoch 2/20\n",
      "447/447 [==============================] - 374s 836ms/step - loss: 10.2946 - accuracy: 0.2339 - f1_m: 0.2141 - precision_m: 0.1284 - recall_m: 0.6422\n",
      "Epoch 3/20\n",
      "447/447 [==============================] - 377s 843ms/step - loss: 10.3194 - accuracy: 0.2324 - f1_m: 0.2141 - precision_m: 0.1284 - recall_m: 0.6422\n",
      "Epoch 4/20\n",
      "447/447 [==============================] - 376s 841ms/step - loss: 10.3013 - accuracy: 0.2328 - f1_m: 0.2141 - precision_m: 0.1284 - recall_m: 0.6422\n",
      "Epoch 5/20\n",
      "447/447 [==============================] - 375s 839ms/step - loss: 10.3013 - accuracy: 0.2331 - f1_m: 0.2141 - precision_m: 0.1284 - recall_m: 0.6422\n",
      "Epoch 6/20\n",
      "177/447 [==========>...................] - ETA: 3:47 - loss: 10.3100 - accuracy: 0.2346 - f1_m: 0.2145 - precision_m: 0.1287 - recall_m: 0.6435"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-d28eed0889c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvit_classifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-69-bcbf16d5c488>\u001b[0m in \u001b[0;36mrun_experiment\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     history = model.fit(\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2494\u001b[0m       (graph_function,\n\u001b[0;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2497\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1860\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1861\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1863\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = run_experiment(vit_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77908e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cf1368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
